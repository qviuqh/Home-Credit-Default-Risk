{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c44dd60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:46:24.666352Z",
     "iopub.status.busy": "2024-12-07T02:46:24.665915Z",
     "iopub.status.idle": "2024-12-07T02:46:28.213039Z",
     "shell.execute_reply": "2024-12-07T02:46:28.211218Z"
    },
    "papermill": {
     "duration": 3.556844,
     "end_time": "2024-12-07T02:46:28.215678",
     "exception": false,
     "start_time": "2024-12-07T02:46:24.658834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing Useful DataStructures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#importing plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from prettytable import PrettyTable\n",
    "\n",
    "#importing Misc Libraries\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "\n",
    "#for 100% jupyter notebook cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f35ac51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:46:28.231590Z",
     "iopub.status.busy": "2024-12-07T02:46:28.230672Z",
     "iopub.status.idle": "2024-12-07T02:46:29.705133Z",
     "shell.execute_reply": "2024-12-07T02:46:29.703735Z"
    },
    "papermill": {
     "duration": 1.484946,
     "end_time": "2024-12-07T02:46:29.707677",
     "exception": false,
     "start_time": "2024-12-07T02:46:28.222731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import XGBClassifier từ thư viện XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Import LGBMClassifier từ thư viện LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d63013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:46:29.719835Z",
     "iopub.status.busy": "2024-12-07T02:46:29.719216Z",
     "iopub.status.idle": "2024-12-07T02:46:39.865010Z",
     "shell.execute_reply": "2024-12-07T02:46:39.863489Z"
    },
    "papermill": {
     "duration": 10.155245,
     "end_time": "2024-12-07T02:46:39.868095",
     "exception": false,
     "start_time": "2024-12-07T02:46:29.712850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Đường dẫn tới file .pkl\n",
    "data_path = '/kaggle/input/data-final/train_data_final.pkl'\n",
    "test_path = '/kaggle/input/data-final/test_data_final.pkl'\n",
    "# Mở file .pkl và đọc dữ liệu\n",
    "with open(data_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "with open(test_path, 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447c0e14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:46:39.882086Z",
     "iopub.status.busy": "2024-12-07T02:46:39.880393Z",
     "iopub.status.idle": "2024-12-07T02:46:42.979209Z",
     "shell.execute_reply": "2024-12-07T02:46:42.978024Z"
    },
    "papermill": {
     "duration": 3.108851,
     "end_time": "2024-12-07T02:46:42.982152",
     "exception": false,
     "start_time": "2024-12-07T02:46:39.873301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(labels=\"Unnamed: 0\",axis=1,inplace=True)\n",
    "test.drop(labels=\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1fc933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:46:42.995566Z",
     "iopub.status.busy": "2024-12-07T02:46:42.994679Z",
     "iopub.status.idle": "2024-12-07T02:46:44.538205Z",
     "shell.execute_reply": "2024-12-07T02:46:44.536972Z"
    },
    "papermill": {
     "duration": 1.553574,
     "end_time": "2024-12-07T02:46:44.541002",
     "exception": false,
     "start_time": "2024-12-07T02:46:42.987428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = data[[\"TARGET\"]]\n",
    "X = data.drop(columns=[\"TARGET\"])\n",
    "# Tạm thời del data và test để tối ưu RAM\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943445cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:46:44.553658Z",
     "iopub.status.busy": "2024-12-07T02:46:44.553271Z",
     "iopub.status.idle": "2024-12-07T02:46:53.843010Z",
     "shell.execute_reply": "2024-12-07T02:46:53.841776Z"
    },
    "papermill": {
     "duration": 9.299916,
     "end_time": "2024-12-07T02:46:53.845990",
     "exception": false,
     "start_time": "2024-12-07T02:46:44.546074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23 columns with just 1 unique value\n",
      "Removing these from dataset\n"
     ]
    }
   ],
   "source": [
    "empty_columns = []\n",
    "for col in X.columns:\n",
    "    if len(X[col].unique()) <=1:\n",
    "        empty_columns.append(col)\n",
    "    \n",
    "print(f\"There are {len(empty_columns)} columns with just 1 unique value\")\n",
    "print(\"Removing these from dataset\")\n",
    "X = X.drop(empty_columns, axis = 1)\n",
    "test = test.drop(empty_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a7a8f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:46:53.884540Z",
     "iopub.status.busy": "2024-12-07T02:46:53.884139Z",
     "iopub.status.idle": "2024-12-07T02:46:55.455706Z",
     "shell.execute_reply": "2024-12-07T02:46:55.454445Z"
    },
    "papermill": {
     "duration": 1.581889,
     "end_time": "2024-12-07T02:46:55.458381",
     "exception": false,
     "start_time": "2024-12-07T02:46:53.876492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing the SK_ID_CURR from training and test data\n",
    "X = X.drop(['SK_ID_CURR'], axis = 1)\n",
    "skid_test = test.pop('SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8fcd9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:46:55.471321Z",
     "iopub.status.busy": "2024-12-07T02:46:55.469788Z",
     "iopub.status.idle": "2024-12-07T02:47:02.769836Z",
     "shell.execute_reply": "2024-12-07T02:47:02.768706Z"
    },
    "papermill": {
     "duration": 7.308933,
     "end_time": "2024-12-07T02:47:02.772277",
     "exception": false,
     "start_time": "2024-12-07T02:46:55.463344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#standardizing the data\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# test = scaler.fit_transform(test)\n",
    "#replacing nan values with 0\n",
    "X[np.isnan(X)] = 0\n",
    "test[np.isnan(test)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a7efd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:47:02.784280Z",
     "iopub.status.busy": "2024-12-07T02:47:02.783857Z",
     "iopub.status.idle": "2024-12-07T02:47:02.827727Z",
     "shell.execute_reply": "2024-12-07T02:47:02.826261Z"
    },
    "papermill": {
     "duration": 0.052935,
     "end_time": "2024-12-07T02:47:02.830455",
     "exception": false,
     "start_time": "2024-12-07T02:47:02.777520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f94bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:47:02.842595Z",
     "iopub.status.busy": "2024-12-07T02:47:02.842190Z",
     "iopub.status.idle": "2024-12-07T02:47:02.877744Z",
     "shell.execute_reply": "2024-12-07T02:47:02.876093Z"
    },
    "papermill": {
     "duration": 0.045634,
     "end_time": "2024-12-07T02:47:02.881130",
     "exception": false,
     "start_time": "2024-12-07T02:47:02.835496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class modelling:\n",
    "    '''\n",
    "    Class for Doing Hyperparameter tuning to find best set of hyperparameters, building models on best hyperparams and\n",
    "    displaying results on best hyperparameters.\n",
    "    \n",
    "    It has 4 methods:\n",
    "        1. init method\n",
    "        2. random_search_cv method\n",
    "        3. train_on_best_params method\n",
    "        4. proba_to_class method\n",
    "        5. tune_threshold method\n",
    "        6. results_on_best_params method\n",
    "        7. feat_importances_show method\n",
    "    '''\n",
    "    def __init__(self, base_model, x_train, y_train, x_test, calibration = False, calibration_method = 'isotonic',\n",
    "                 calibration_cv = 4, k_folds = 4, random_state = 42):\n",
    "        '''\n",
    "        Function to initialize the class members.\n",
    "        \n",
    "        Inputs: \n",
    "            self\n",
    "            base_model: estimator/classifier\n",
    "                The base model to be used for the modelling purpose\n",
    "            x_train: numpy array\n",
    "                Training standardized data\n",
    "            y_train: numpy array\n",
    "                Training class labels\n",
    "            x_test: numpy array\n",
    "                Test standardized data\n",
    "            calibration: bool, default = False\n",
    "                Whether to calibrate the model for generating class probabilities\n",
    "            calibration_method: str, default = 'isotonic'\n",
    "                The type of calibration to use, i.e. sigmoid or isotonic\n",
    "            calibration_cv: int, default = 4\n",
    "                Number of cross-validation folds for calibrating the probabilities\n",
    "            k_folds: int, default = 4\n",
    "                Number of cross-validation folds for training and tuning the model\n",
    "            random_state: int, default = 42\n",
    "                Random state for StratifiedKFold for reproducibility\n",
    "                \n",
    "        Returns: \n",
    "            None            \n",
    "        '''\n",
    "        self.base_model = base_model\n",
    "        self.num_folds = k_folds\n",
    "        self.kfolds = StratifiedKFold(n_splits = k_folds, shuffle = True, random_state = random_state)\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.calibration = calibration\n",
    "        if self.calibration:\n",
    "            self.calibration_method = calibration_method\n",
    "            self.calibration_cv = calibration_cv\n",
    "\n",
    "    def random_search_cv(self, hyperparams_dict, n_iter = 30, verbose = True, n_jobs = 1, random_state = 42):\n",
    "        '''\n",
    "        Function to do RandomizedSearchCV on training data.\n",
    "        \n",
    "        Inputs:\n",
    "            self\n",
    "            hyperparams_dict: dict\n",
    "                Dictionary of hyperparameters to tune\n",
    "            n_iter: int, default = 30\n",
    "                Number of iterations to perform for random search\n",
    "            verbose: bool, default = True\n",
    "                Whether to keep verbosity or not\n",
    "            n_jobs: int, default = 1\n",
    "                Number of cores to use for Random Search\n",
    "            random_state: int, default = 42\n",
    "                Random state for reproducibility of RandomizedSearchCV\n",
    "                \n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        if verbose:\n",
    "            start = datetime.now()\n",
    "            print(f\"Doing Randomized Search CV on Classifier with {n_iter} random initializations...\")\n",
    "        rscv = RandomizedSearchCV(self.base_model, hyperparams_dict, n_iter = n_iter, scoring = 'roc_auc', \n",
    "                                  cv = self.kfolds, return_train_score = True, verbose = 2,\n",
    "                                  n_jobs = n_jobs, random_state = random_state)\n",
    "        rscv.fit(self.x_train, self.y_train)\n",
    "        if verbose:\n",
    "            print(\"Done.\")\n",
    "            print(f\"Time elapsed = {datetime.now() - start}\")\n",
    "        \n",
    "        #getting the Search Results\n",
    "        self.tuning_results = pd.DataFrame(rscv.cv_results_)\n",
    "        #best model\n",
    "        self.best_model = rscv.best_estimator_\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def grid_search_cv(self, hyperparams_dict, verbose=True, n_jobs=1):\n",
    "        '''\n",
    "        Function to do GridSearchCV on training data.\n",
    "        \n",
    "        Inputs:\n",
    "            self\n",
    "            hyperparams_dict: dict\n",
    "                Dictionary of hyperparameters to tune\n",
    "            verbose: bool, default = True\n",
    "                Whether to keep verbosity or not\n",
    "            n_jobs: int, default = 1\n",
    "                Number of cores to use for Grid Search\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        if verbose:\n",
    "            start = datetime.now()\n",
    "            print(\"Performing Grid Search CV on Classifier...\")\n",
    "        \n",
    "        gscv = GridSearchCV(self.base_model, hyperparams_dict, scoring='roc_auc', \n",
    "                            cv=self.kfolds, return_train_score=True, \n",
    "                            verbose=2, n_jobs=n_jobs)\n",
    "    \n",
    "        gscv.fit(self.x_train, self.y_train)\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"Done.\")\n",
    "            print(f\"Time elapsed = {datetime.now() - start}\")\n",
    "        \n",
    "        # Getting the Search Results\n",
    "        self.tuning_results = pd.DataFrame(gscv.cv_results_)\n",
    "        # Best model\n",
    "        self.best_model = gscv.best_estimator_\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    \n",
    "    def train_on_best_params(self, verbose = True):\n",
    "        '''\n",
    "        Function to train the model on best hyperparameters obtained from previous method.\n",
    "        Generates Cross-Validation predictions as Out-of-fold predictions\n",
    "        \n",
    "        Inputs:\n",
    "            self\n",
    "            verbose: bool, default = True\n",
    "                Whether to keep verbosity or not\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Fitting Classifier on best parameters\\n\")\n",
    "            print(f\"{self.num_folds}-Fold Cross Validation\")\n",
    "            start = datetime.now()\n",
    "            \n",
    "        self.cv_preds_probas = np.zeros(self.x_train.shape[0])\n",
    "        #we will select a best threshold for each fold of cross-validation and average over the\n",
    "        #folds to find the optimal threshold\n",
    "        self.best_threshold_train = 0\n",
    "        for fold_number, (train_indices, val_indices) in enumerate(self.kfolds.split(self.x_train, self.y_train), 1):\n",
    "            if verbose:\n",
    "                print(f\"\\tFitting Fold {fold_number}\")\n",
    "                \n",
    "            self.best_model.fit(self.x_train.iloc[train_indices], self.y_train.iloc[train_indices])\n",
    "            if not self.calibration:\n",
    "                self.train_preds_probas = self.best_model.predict_proba(self.x_train.iloc[train_indices])[:,1]\n",
    "                self.cv_preds_probas[val_indices] = self.best_model.predict_proba(self.x_train.iloc[val_indices])[:,1]\n",
    "            else:\n",
    "                #fitting the calibration Classifier over the base model for calibrated probabilities\n",
    "                self.calibrated_classifier = CalibratedClassifierCV(self.best_model, method = self.calibration_method, cv = self.calibration_cv)\n",
    "                self.calibrated_classifier.fit(self.x_train.iloc[train_indices], self.y_train.iloc[train_indices])\n",
    "                \n",
    "                self.train_preds_probas = self.calibrated_classifier.predict_proba(self.x_train.iloc[train_indices])[:,1]\n",
    "                self.cv_preds_probas[val_indices] = self.calibrated_classifier.predict_proba(self.x_train.iloc[val_indices])[:,1]\n",
    "            \n",
    "            #tuning the threshold for optimal TPR and FPR from ROC Curve\n",
    "            self.best_threshold_train += self.tune_threshold(self.y_train.iloc[train_indices], self.train_preds_probas) / self.num_folds\n",
    "        \n",
    "        #converting the class probabilities to class labels\n",
    "        self.cv_preds_class = self.proba_to_class(self.cv_preds_probas, self.best_threshold_train)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Done.\")\n",
    "            print(f\"Time elapsed = {datetime.now() - start}\")\n",
    "            \n",
    "        gc.collect()\n",
    "    \n",
    "    def proba_to_class(self, proba, threshold):\n",
    "        '''\n",
    "        Function to convert a given probability to class label based on a threshold value.\n",
    "        \n",
    "        Inputs:\n",
    "            self\n",
    "            proba: numpy array\n",
    "                Probabilities of class label = 1\n",
    "            threshold: int\n",
    "                Threshold probability to be considered as Positive or Negative Class Label\n",
    "            \n",
    "        Returns:\n",
    "            Converted Class Label\n",
    "        '''\n",
    "        return np.where(proba >= threshold, 1, 0)\n",
    "\n",
    "    # def tune_threshold(self, true_labels, predicted_probas):\n",
    "    #     '''\n",
    "    #     Function to find the optimal threshold for minimizing False Negatives (maximize Recall/TPR).\n",
    "        \n",
    "    #     Inputs:\n",
    "    #         self\n",
    "    #         true_labels: numpy array or pandas series\n",
    "    #             True Class Labels\n",
    "    #         predicted_probas: numpy array\n",
    "    #             Predicted Probabilities for the Positive Class\n",
    "                    \n",
    "    #     Returns:\n",
    "    #         Optimal threshold probability\n",
    "    #     '''\n",
    "    #     # Calculate the ROC curve\n",
    "    #     fpr, tpr, thresholds = roc_curve(true_labels, predicted_probas)\n",
    "        \n",
    "    #     # To minimize false negatives, maximize recall (TPR)\n",
    "    #     # Find the threshold corresponding to the maximum TPR\n",
    "    #     optimal_index = np.argmax(tpr)  # Find the index of the highest TPR\n",
    "    #     optimal_threshold = thresholds[optimal_index]\n",
    "    \n",
    "    #     print(f\"Optimal Threshold (to minimize false negatives): {optimal_threshold}\")\n",
    "    #     return optimal_threshold\n",
    "\n",
    "    def tune_threshold(self, true_labels, predicted_probas):\n",
    "        '''\n",
    "        Function to find the optimal threshold for maximizing the TPR and minimizing the FPR from ROC-AUC Curve.\n",
    "        This is found out by using the J Statistic, which is J = TPR - FPR.\n",
    "        Reference: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "        \n",
    "        Inputs:\n",
    "            self\n",
    "            true_labels: numpy array or pandas series\n",
    "                True Class Labels\n",
    "            predicted_probas: numpy array\n",
    "                Predicted Probability of Positive Class label\n",
    "            \n",
    "        Returns:\n",
    "            Threshold probability.\n",
    "        '''\n",
    "        fpr, tpr, threshold = roc_curve(true_labels, predicted_probas)\n",
    "        j_stat = tpr - fpr\n",
    "        index_for_best_threshold = np.argmax(j_stat)\n",
    "        \n",
    "        return threshold[index_for_best_threshold]\n",
    "        \n",
    "    def results_on_best_params(self, model_name):\n",
    "        '''\n",
    "        Function to train the whole data on best parameters and display the results.\n",
    "        \n",
    "        Inputs:\n",
    "            self\n",
    "            model_name: str\n",
    "                model name to get feature importances.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        #we have to fit the whole model for optimal test predictions\n",
    "        self.best_model.fit(self.x_train, self.y_train)\n",
    "        if not self.calibration:\n",
    "            self.train_preds_probas = self.best_model.predict_proba(self.x_train)[:,1]\n",
    "            self.test_preds_probas = self.best_model.predict_proba(self.x_test)[:,1]\n",
    "        else:\n",
    "            #fitting calibration model over whole training data for test predictions\n",
    "            self.calibrated_classifier.fit(self.x_train, self.y_train)\n",
    "            self.train_preds_probas = self.calibrated_classifier.predict_proba(self.x_train)[:,1]\n",
    "            self.test_preds_probas = self.calibrated_classifier.predict_proba(self.x_test)[:,1]\n",
    "        \n",
    "        #getting class labels from probabilities\n",
    "        self.train_preds_class = self.proba_to_class(self.train_preds_probas, self.best_threshold_train)\n",
    "        self.test_preds_class = self.proba_to_class(self.test_preds_probas, self.best_threshold_train)\n",
    "        \n",
    "        #feature importances\n",
    "        if model_name == 'linear':\n",
    "            self.feat_imp = self.best_model.coef_[0]\n",
    "        else:\n",
    "            self.feat_imp = self.best_model.feature_importances_\n",
    "                \n",
    "        print(\"=\" * 100)\n",
    "        print(f\"\\nThe best selected Threshold as per the J-Statistic, which is J = TPR - FPR, is = {self.best_threshold_train}\\n\")\n",
    "        print(\"Train Results:\")\n",
    "        print(f\"\\tROC-AUC Score = {roc_auc_score(self.y_train, self.train_preds_probas)}\")\n",
    "        print(f\"\\tPrecision Score = {precision_score(self.y_train, self.train_preds_class)}\")\n",
    "        print(f\"\\tRecall Score = {recall_score(self.y_train, self.train_preds_class)}\")\n",
    "        print(\"CV Results:\")\n",
    "        print(f\"\\tROC-AUC Score = {roc_auc_score(self.y_train, self.cv_preds_probas)}\")\n",
    "        print(f\"\\tPrecision Score = {precision_score(self.y_train, self.cv_preds_class)}\")\n",
    "        print(f\"\\tRecall Score = {recall_score(self.y_train, self.cv_preds_class)}\")\n",
    "\n",
    "        print('=' * 100)\n",
    "        print(\"Confusion Matrix of CV data:\")\n",
    "        conf_mat = confusion_matrix(self.y_train, self.cv_preds_class)\n",
    "        conf_mat = pd.DataFrame(conf_mat, columns = ['Predicted_0','Predicted_1'], index = ['Actual_0','Actual_1'])\n",
    "        plt.figure(figsize = (7,6))\n",
    "        plt.title('Confusion Matrix Heatmap')\n",
    "        sns.heatmap(conf_mat, annot = True, fmt = 'g', linewidth = 0.5, annot_kws = {'size' : 15})\n",
    "        plt.show()\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "    def feat_importances_show(self, feature_names, num_features, figsize = (10,15)):\n",
    "        '''\n",
    "        Function to display the top most important features.\n",
    "        \n",
    "        Inputs:\n",
    "            self\n",
    "            feature_names: numpy array\n",
    "                Names of features of training set\n",
    "            num_features: int\n",
    "                Number of top features importances to display\n",
    "            figsize: tuple, default = (10,15)\n",
    "                Size of figure to be displayed\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        #getting the top features indices and their names\n",
    "        top_feats_indices = np.argsort(self.feat_imp)[::-1][:num_features]\n",
    "        feat_importance_top = self.feat_imp[top_feats_indices]\n",
    "        column_names = feature_names[top_feats_indices]\n",
    "        \n",
    "        #plotting a horizontal bar plot of feature importances\n",
    "        plt.figure(figsize = figsize) \n",
    "        sns.barplot(feat_importance_top, list(range(num_features)), orient = 'h')\n",
    "        plt.yticks(list(range(50)), column_names)\n",
    "        plt.title(f'Top {num_features} features as per classifier')\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.ylabel('Feature Names')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print('=' * 100)\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4704a383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:47:02.893233Z",
     "iopub.status.busy": "2024-12-07T02:47:02.892818Z",
     "iopub.status.idle": "2024-12-07T02:47:02.898585Z",
     "shell.execute_reply": "2024-12-07T02:47:02.897401Z"
    },
    "papermill": {
     "duration": 0.014193,
     "end_time": "2024-12-07T02:47:02.900764",
     "exception": false,
     "start_time": "2024-12-07T02:47:02.886571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(max_depth=7,criterion=\"entropy\",class_weight=\"balanced\",random_state=42)\n",
    "\n",
    "model = modelling(base_model=decision_tree, \n",
    "                  x_train=X, \n",
    "                  y_train=y, \n",
    "                  x_test=test,calibration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e035a64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T02:47:02.912461Z",
     "iopub.status.busy": "2024-12-07T02:47:02.912070Z",
     "iopub.status.idle": "2024-12-07T05:13:49.457557Z",
     "shell.execute_reply": "2024-12-07T05:13:49.456272Z"
    },
    "papermill": {
     "duration": 8806.562439,
     "end_time": "2024-12-07T05:13:49.468118",
     "exception": false,
     "start_time": "2024-12-07T02:47:02.905679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Randomized Search CV on Classifier with 30 random initializations...\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=15, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=20; total time= 2.3min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=20; total time= 2.3min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=25, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=35, min_samples_split=50; total time= 2.3min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=10; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=20; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=30; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=30; total time= 2.3min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=50; total time= 2.2min\n",
      "[CV] END ..........min_samples_leaf=50, min_samples_split=50; total time= 2.2min\n",
      "Done.\n",
      "Time elapsed = 2:26:46.421815\n"
     ]
    }
   ],
   "source": [
    "# Từ điển siêu tham số cho Decision Tree\n",
    "# hyperparams_dict = {\n",
    "#     'max_depth': [9, 15, 20, 25, None],\n",
    "#     'min_samples_split': [2, 5, 10, 20, None],\n",
    "#     'min_samples_leaf': [1, 2, 5, 10, None],\n",
    "#     # 'max_features':['auto','sqrt','log2']\n",
    "# }\n",
    "\n",
    "hyperparams_dict = {\n",
    "    # \"max_depth\": [5, 7, 15, 20, 30],\n",
    "    \"min_samples_split\": [10, 20, 30, 50],\n",
    "    \"min_samples_leaf\": [15, 25, 35, 50]\n",
    "}\n",
    "    # 'min_samples_split': [2, 5, 10],\n",
    "    # 'min_samples_leaf': [1, 2, 4]\n",
    ",\n",
    "# Tuning siêu tham số với RandomizedSearchCV\n",
    "# model.grid_search_cv(hyperparams_dict, verbose=True, n_jobs=1)\n",
    "model.random_search_cv(hyperparams_dict=hyperparams_dict, n_iter=30, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a29a4cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T05:13:49.487295Z",
     "iopub.status.busy": "2024-12-07T05:13:49.486856Z",
     "iopub.status.idle": "2024-12-07T05:13:49.523163Z",
     "shell.execute_reply": "2024-12-07T05:13:49.522007Z"
    },
    "papermill": {
     "duration": 0.049362,
     "end_time": "2024-12-07T05:13:49.525787",
     "exception": false,
     "start_time": "2024-12-07T05:13:49.476425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132.576847</td>\n",
       "      <td>0.885735</td>\n",
       "      <td>0.488689</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_split': 10, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.748017</td>\n",
       "      <td>0.755842</td>\n",
       "      <td>0.753158</td>\n",
       "      <td>0.752018</td>\n",
       "      <td>0.752259</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>9</td>\n",
       "      <td>0.772514</td>\n",
       "      <td>0.769792</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.770611</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133.063214</td>\n",
       "      <td>0.460752</td>\n",
       "      <td>0.504319</td>\n",
       "      <td>0.019282</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.748017</td>\n",
       "      <td>0.755842</td>\n",
       "      <td>0.753158</td>\n",
       "      <td>0.752018</td>\n",
       "      <td>0.752259</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>9</td>\n",
       "      <td>0.772514</td>\n",
       "      <td>0.769792</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.770611</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.114480</td>\n",
       "      <td>0.550937</td>\n",
       "      <td>0.495671</td>\n",
       "      <td>0.012586</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_split': 30, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.748017</td>\n",
       "      <td>0.755842</td>\n",
       "      <td>0.753158</td>\n",
       "      <td>0.752018</td>\n",
       "      <td>0.752259</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>9</td>\n",
       "      <td>0.772514</td>\n",
       "      <td>0.769792</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.770611</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132.741091</td>\n",
       "      <td>0.648875</td>\n",
       "      <td>0.495069</td>\n",
       "      <td>0.016110</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_split': 50, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.748101</td>\n",
       "      <td>0.755842</td>\n",
       "      <td>0.753158</td>\n",
       "      <td>0.751831</td>\n",
       "      <td>0.752233</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>16</td>\n",
       "      <td>0.772498</td>\n",
       "      <td>0.769792</td>\n",
       "      <td>0.770200</td>\n",
       "      <td>0.770450</td>\n",
       "      <td>0.770735</td>\n",
       "      <td>0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.922090</td>\n",
       "      <td>0.941208</td>\n",
       "      <td>0.490392</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'min_samples_split': 10, 'min_samples_leaf': 25}</td>\n",
       "      <td>0.748992</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>0.753029</td>\n",
       "      <td>0.750740</td>\n",
       "      <td>0.752240</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>12</td>\n",
       "      <td>0.772531</td>\n",
       "      <td>0.769670</td>\n",
       "      <td>0.770121</td>\n",
       "      <td>0.770439</td>\n",
       "      <td>0.770691</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>134.135821</td>\n",
       "      <td>1.163734</td>\n",
       "      <td>0.506568</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': 25}</td>\n",
       "      <td>0.748992</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>0.753029</td>\n",
       "      <td>0.750740</td>\n",
       "      <td>0.752240</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>12</td>\n",
       "      <td>0.772531</td>\n",
       "      <td>0.769670</td>\n",
       "      <td>0.770121</td>\n",
       "      <td>0.770439</td>\n",
       "      <td>0.770691</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132.615926</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.520158</td>\n",
       "      <td>0.046178</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>{'min_samples_split': 30, 'min_samples_leaf': 25}</td>\n",
       "      <td>0.748992</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>0.753029</td>\n",
       "      <td>0.750740</td>\n",
       "      <td>0.752240</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>12</td>\n",
       "      <td>0.772531</td>\n",
       "      <td>0.769670</td>\n",
       "      <td>0.770121</td>\n",
       "      <td>0.770439</td>\n",
       "      <td>0.770691</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>131.926074</td>\n",
       "      <td>0.345220</td>\n",
       "      <td>0.532831</td>\n",
       "      <td>0.056590</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>{'min_samples_split': 50, 'min_samples_leaf': 25}</td>\n",
       "      <td>0.748992</td>\n",
       "      <td>0.756200</td>\n",
       "      <td>0.753029</td>\n",
       "      <td>0.750740</td>\n",
       "      <td>0.752240</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>12</td>\n",
       "      <td>0.772531</td>\n",
       "      <td>0.769670</td>\n",
       "      <td>0.770121</td>\n",
       "      <td>0.770439</td>\n",
       "      <td>0.770691</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>132.559230</td>\n",
       "      <td>0.237550</td>\n",
       "      <td>0.486568</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>{'min_samples_split': 10, 'min_samples_leaf': 35}</td>\n",
       "      <td>0.749450</td>\n",
       "      <td>0.756535</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>0.750678</td>\n",
       "      <td>0.752890</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>5</td>\n",
       "      <td>0.772375</td>\n",
       "      <td>0.769494</td>\n",
       "      <td>0.770040</td>\n",
       "      <td>0.770483</td>\n",
       "      <td>0.770598</td>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132.971254</td>\n",
       "      <td>0.527649</td>\n",
       "      <td>0.490235</td>\n",
       "      <td>0.007197</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': 35}</td>\n",
       "      <td>0.749450</td>\n",
       "      <td>0.756535</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>0.750678</td>\n",
       "      <td>0.752890</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>5</td>\n",
       "      <td>0.772375</td>\n",
       "      <td>0.769494</td>\n",
       "      <td>0.770040</td>\n",
       "      <td>0.770483</td>\n",
       "      <td>0.770598</td>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>132.732117</td>\n",
       "      <td>0.375449</td>\n",
       "      <td>0.486410</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>{'min_samples_split': 30, 'min_samples_leaf': 35}</td>\n",
       "      <td>0.749450</td>\n",
       "      <td>0.756535</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>0.750678</td>\n",
       "      <td>0.752890</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>5</td>\n",
       "      <td>0.772375</td>\n",
       "      <td>0.769494</td>\n",
       "      <td>0.770040</td>\n",
       "      <td>0.770483</td>\n",
       "      <td>0.770598</td>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>133.368032</td>\n",
       "      <td>1.917964</td>\n",
       "      <td>0.497134</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>{'min_samples_split': 50, 'min_samples_leaf': 35}</td>\n",
       "      <td>0.749450</td>\n",
       "      <td>0.756535</td>\n",
       "      <td>0.754897</td>\n",
       "      <td>0.750678</td>\n",
       "      <td>0.752890</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>5</td>\n",
       "      <td>0.772375</td>\n",
       "      <td>0.769494</td>\n",
       "      <td>0.770040</td>\n",
       "      <td>0.770483</td>\n",
       "      <td>0.770598</td>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>132.649178</td>\n",
       "      <td>1.335087</td>\n",
       "      <td>0.520314</td>\n",
       "      <td>0.057095</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 10, 'min_samples_leaf': 50}</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>132.089650</td>\n",
       "      <td>0.546949</td>\n",
       "      <td>0.495170</td>\n",
       "      <td>0.015660</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': 50}</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>133.080460</td>\n",
       "      <td>1.215974</td>\n",
       "      <td>0.525505</td>\n",
       "      <td>0.048704</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 30, 'min_samples_leaf': 50}</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>132.698911</td>\n",
       "      <td>0.635115</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 50, 'min_samples_leaf': 50}</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      132.576847      0.885735         0.488689        0.006199   \n",
       "1      133.063214      0.460752         0.504319        0.019282   \n",
       "2      133.114480      0.550937         0.495671        0.012586   \n",
       "3      132.741091      0.648875         0.495069        0.016110   \n",
       "4      132.922090      0.941208         0.490392        0.005652   \n",
       "5      134.135821      1.163734         0.506568        0.013258   \n",
       "6      132.615926      0.360656         0.520158        0.046178   \n",
       "7      131.926074      0.345220         0.532831        0.056590   \n",
       "8      132.559230      0.237550         0.486568        0.002741   \n",
       "9      132.971254      0.527649         0.490235        0.007197   \n",
       "10     132.732117      0.375449         0.486410        0.002524   \n",
       "11     133.368032      1.917964         0.497134        0.017504   \n",
       "12     132.649178      1.335087         0.520314        0.057095   \n",
       "13     132.089650      0.546949         0.495170        0.015660   \n",
       "14     133.080460      1.215974         0.525505        0.048704   \n",
       "15     132.698911      0.635115         0.492404        0.010156   \n",
       "\n",
       "   param_min_samples_split param_min_samples_leaf  \\\n",
       "0                       10                     15   \n",
       "1                       20                     15   \n",
       "2                       30                     15   \n",
       "3                       50                     15   \n",
       "4                       10                     25   \n",
       "5                       20                     25   \n",
       "6                       30                     25   \n",
       "7                       50                     25   \n",
       "8                       10                     35   \n",
       "9                       20                     35   \n",
       "10                      30                     35   \n",
       "11                      50                     35   \n",
       "12                      10                     50   \n",
       "13                      20                     50   \n",
       "14                      30                     50   \n",
       "15                      50                     50   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'min_samples_split': 10, 'min_samples_leaf': 15}           0.748017   \n",
       "1   {'min_samples_split': 20, 'min_samples_leaf': 15}           0.748017   \n",
       "2   {'min_samples_split': 30, 'min_samples_leaf': 15}           0.748017   \n",
       "3   {'min_samples_split': 50, 'min_samples_leaf': 15}           0.748101   \n",
       "4   {'min_samples_split': 10, 'min_samples_leaf': 25}           0.748992   \n",
       "5   {'min_samples_split': 20, 'min_samples_leaf': 25}           0.748992   \n",
       "6   {'min_samples_split': 30, 'min_samples_leaf': 25}           0.748992   \n",
       "7   {'min_samples_split': 50, 'min_samples_leaf': 25}           0.748992   \n",
       "8   {'min_samples_split': 10, 'min_samples_leaf': 35}           0.749450   \n",
       "9   {'min_samples_split': 20, 'min_samples_leaf': 35}           0.749450   \n",
       "10  {'min_samples_split': 30, 'min_samples_leaf': 35}           0.749450   \n",
       "11  {'min_samples_split': 50, 'min_samples_leaf': 35}           0.749450   \n",
       "12  {'min_samples_split': 10, 'min_samples_leaf': 50}           0.749961   \n",
       "13  {'min_samples_split': 20, 'min_samples_leaf': 50}           0.749961   \n",
       "14  {'min_samples_split': 30, 'min_samples_leaf': 50}           0.749961   \n",
       "15  {'min_samples_split': 50, 'min_samples_leaf': 50}           0.749961   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0            0.755842           0.753158           0.752018         0.752259   \n",
       "1            0.755842           0.753158           0.752018         0.752259   \n",
       "2            0.755842           0.753158           0.752018         0.752259   \n",
       "3            0.755842           0.753158           0.751831         0.752233   \n",
       "4            0.756200           0.753029           0.750740         0.752240   \n",
       "5            0.756200           0.753029           0.750740         0.752240   \n",
       "6            0.756200           0.753029           0.750740         0.752240   \n",
       "7            0.756200           0.753029           0.750740         0.752240   \n",
       "8            0.756535           0.754897           0.750678         0.752890   \n",
       "9            0.756535           0.754897           0.750678         0.752890   \n",
       "10           0.756535           0.754897           0.750678         0.752890   \n",
       "11           0.756535           0.754897           0.750678         0.752890   \n",
       "12           0.756909           0.755331           0.750905         0.753277   \n",
       "13           0.756909           0.755331           0.750905         0.753277   \n",
       "14           0.756909           0.755331           0.750905         0.753277   \n",
       "15           0.756909           0.755331           0.750905         0.753277   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.002815                9            0.772514            0.769792   \n",
       "1         0.002815                9            0.772514            0.769792   \n",
       "2         0.002815                9            0.772514            0.769792   \n",
       "3         0.002789               16            0.772498            0.769792   \n",
       "4         0.002698               12            0.772531            0.769670   \n",
       "5         0.002698               12            0.772531            0.769670   \n",
       "6         0.002698               12            0.772531            0.769670   \n",
       "7         0.002698               12            0.772531            0.769670   \n",
       "8         0.002917                5            0.772375            0.769494   \n",
       "9         0.002917                5            0.772375            0.769494   \n",
       "10        0.002917                5            0.772375            0.769494   \n",
       "11        0.002917                5            0.772375            0.769494   \n",
       "12        0.002917                1            0.771966            0.769311   \n",
       "13        0.002917                1            0.771966            0.769311   \n",
       "14        0.002917                1            0.771966            0.769311   \n",
       "15        0.002917                1            0.771966            0.769311   \n",
       "\n",
       "    split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0             0.770200            0.770611          0.770779         0.001043  \n",
       "1             0.770200            0.770611          0.770779         0.001043  \n",
       "2             0.770200            0.770611          0.770779         0.001043  \n",
       "3             0.770200            0.770450          0.770735         0.001045  \n",
       "4             0.770121            0.770439          0.770691         0.001097  \n",
       "5             0.770121            0.770439          0.770691         0.001097  \n",
       "6             0.770121            0.770439          0.770691         0.001097  \n",
       "7             0.770121            0.770439          0.770691         0.001097  \n",
       "8             0.770040            0.770483          0.770598         0.001084  \n",
       "9             0.770040            0.770483          0.770598         0.001084  \n",
       "10            0.770040            0.770483          0.770598         0.001084  \n",
       "11            0.770040            0.770483          0.770598         0.001084  \n",
       "12            0.769646            0.770569          0.770373         0.001029  \n",
       "13            0.769646            0.770569          0.770373         0.001029  \n",
       "14            0.769646            0.770569          0.770373         0.001029  \n",
       "15            0.769646            0.770569          0.770373         0.001029  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turning_res = model.tuning_results\n",
    "turning_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f511a4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T05:13:49.547150Z",
     "iopub.status.busy": "2024-12-07T05:13:49.545849Z",
     "iopub.status.idle": "2024-12-07T05:25:43.115398Z",
     "shell.execute_reply": "2024-12-07T05:25:43.114230Z"
    },
    "papermill": {
     "duration": 713.582085,
     "end_time": "2024-12-07T05:25:43.117592",
     "exception": false,
     "start_time": "2024-12-07T05:13:49.535507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Classifier on best parameters\n",
      "\n",
      "4-Fold Cross Validation\n",
      "\tFitting Fold 1\n",
      "\tFitting Fold 2\n",
      "\tFitting Fold 3\n",
      "\tFitting Fold 4\n",
      "Done.\n",
      "Time elapsed = 0:08:54.389180\n",
      "====================================================================================================\n",
      "\n",
      "The best selected Threshold as per the J-Statistic, which is J = TPR - FPR, is = 0.5210105650562783\n",
      "\n",
      "Train Results:\n",
      "\tROC-AUC Score = 0.7681326665292977\n",
      "\tPrecision Score = 0.1868104089219331\n",
      "\tRecall Score = 0.6320688267256993\n",
      "CV Results:\n",
      "\tROC-AUC Score = 0.7531399641737558\n",
      "\tPrecision Score = 0.16659559524406764\n",
      "\tRecall Score = 0.668293419199034\n",
      "====================================================================================================\n",
      "Confusion Matrix of CV data:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Huấn luyện mô hình với bộ siêu tham số tối ưu\n",
    "model.train_on_best_params()\n",
    "# Hiển thị kết quả của mô hình\n",
    "model.results_on_best_params(model_name='tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b7837cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T05:25:43.139600Z",
     "iopub.status.busy": "2024-12-07T05:25:43.139224Z",
     "iopub.status.idle": "2024-12-07T05:25:43.163100Z",
     "shell.execute_reply": "2024-12-07T05:25:43.162021Z"
    },
    "papermill": {
     "duration": 0.037334,
     "end_time": "2024-12-07T05:25:43.165357",
     "exception": false,
     "start_time": "2024-12-07T05:25:43.128023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>132.649178</td>\n",
       "      <td>1.335087</td>\n",
       "      <td>0.520314</td>\n",
       "      <td>0.057095</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 10, 'min_samples_leaf': 50}</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>132.089650</td>\n",
       "      <td>0.546949</td>\n",
       "      <td>0.495170</td>\n",
       "      <td>0.015660</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': 50}</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>133.080460</td>\n",
       "      <td>1.215974</td>\n",
       "      <td>0.525505</td>\n",
       "      <td>0.048704</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 30, 'min_samples_leaf': 50}</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>132.698911</td>\n",
       "      <td>0.635115</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 50, 'min_samples_leaf': 50}</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>0.770569</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12     132.649178      1.335087         0.520314        0.057095   \n",
       "13     132.089650      0.546949         0.495170        0.015660   \n",
       "14     133.080460      1.215974         0.525505        0.048704   \n",
       "15     132.698911      0.635115         0.492404        0.010156   \n",
       "\n",
       "   param_min_samples_split param_min_samples_leaf  \\\n",
       "12                      10                     50   \n",
       "13                      20                     50   \n",
       "14                      30                     50   \n",
       "15                      50                     50   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "12  {'min_samples_split': 10, 'min_samples_leaf': 50}           0.749961   \n",
       "13  {'min_samples_split': 20, 'min_samples_leaf': 50}           0.749961   \n",
       "14  {'min_samples_split': 30, 'min_samples_leaf': 50}           0.749961   \n",
       "15  {'min_samples_split': 50, 'min_samples_leaf': 50}           0.749961   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "12           0.756909           0.755331           0.750905         0.753277   \n",
       "13           0.756909           0.755331           0.750905         0.753277   \n",
       "14           0.756909           0.755331           0.750905         0.753277   \n",
       "15           0.756909           0.755331           0.750905         0.753277   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "12        0.002917                1            0.771966            0.769311   \n",
       "13        0.002917                1            0.771966            0.769311   \n",
       "14        0.002917                1            0.771966            0.769311   \n",
       "15        0.002917                1            0.771966            0.769311   \n",
       "\n",
       "    split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "12            0.769646            0.770569          0.770373         0.001029  \n",
       "13            0.769646            0.770569          0.770373         0.001029  \n",
       "14            0.769646            0.770569          0.770373         0.001029  \n",
       "15            0.769646            0.770569          0.770373         0.001029  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turning_res[turning_res[\"rank_test_score\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc25e52b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T05:25:43.188022Z",
     "iopub.status.busy": "2024-12-07T05:25:43.187600Z",
     "iopub.status.idle": "2024-12-07T05:25:43.330102Z",
     "shell.execute_reply": "2024-12-07T05:25:43.328972Z"
    },
    "papermill": {
     "duration": 0.156656,
     "end_time": "2024-12-07T05:25:43.332527",
     "exception": false,
     "start_time": "2024-12-07T05:25:43.175871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Home Credit Default Risk\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'SK_ID_CURR': skid_test, 'TARGET' : model.test_preds_probas}).to_csv('submission_DT_04.csv',index = False)\n",
    "print('Successfully submitted to Home Credit Default Risk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "815f5a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T05:25:43.356146Z",
     "iopub.status.busy": "2024-12-07T05:25:43.355308Z",
     "iopub.status.idle": "2024-12-07T05:25:43.362536Z",
     "shell.execute_reply": "2024-12-07T05:25:43.361456Z"
    },
    "papermill": {
     "duration": 0.021934,
     "end_time": "2024-12-07T05:25:43.364758",
     "exception": false,
     "start_time": "2024-12-07T05:25:43.342824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('model.pkl','wb') as f:\n",
    "    if not model.calibration: pickle.dump(model.best_model,f)\n",
    "    else: pickle.dump(model.calibrated_classifier,f)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6192473,
     "sourceId": 10050520,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9562.926703,
   "end_time": "2024-12-07T05:25:44.499406",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-07T02:46:21.572703",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
